{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd691aad",
   "metadata": {},
   "source": [
    "# EMPLOYEE PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab754f19",
   "metadata": {},
   "source": [
    "<h1><center>INX FUTURE INC</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11845b1b",
   "metadata": {},
   "source": [
    "- **Candidate Name :** SANDEEP VARUN PATRO\n",
    "- **Candidate E-Mail :** varundriftking1999@gmail.com\n",
    "- **Project Code :** 10281\n",
    "- **Assessment ID :** E10901-PR2-V18\n",
    "- **REP Name :** DataMites™ Solutions Pvt Ltd\n",
    "- **Module :** Certified Data Scientist - Project\n",
    "- **Exam Format :** Open Project- IABAC™ Project Submission\n",
    "- **Project Assessment :** IABAC™\n",
    "- **Registered Trainer :** ASHOK KUMAR A\n",
    "- **Project Starting Date :** 7-April-2023\n",
    "- **Submission Deadline Date:** 17-April-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a613c6",
   "metadata": {},
   "source": [
    "<h1><center>PROJECT SUMMARY</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a768e9b",
   "metadata": {},
   "source": [
    "# Business Case:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00961f",
   "metadata": {},
   "source": [
    "- INX Future Inc , (referred as INX ) , is one of the leading data analytics and automation solutions provider with over 15 years of global business presence. INX is consistently rated as top 20 best employers past 5 years. INX human resource policies are considered as employee friendly and widely perceived as best practices in the industry.\n",
    "- Recent years, the employee performance indexes are not healthy and this is becoming a growing concerns among the top management. There has been increased escalations on service delivery and client satisfaction levels came down by 8 percentage points.CEO, Mr. Brain, knows the issues but concerned to take any actions in penalizing non-performing employees as this would affect the employee morale of all the employees in general and may further reduce the performance. Also, the market perception best employer and thereby attracting best talents to join the company.\n",
    "- Mr. Brain decided to initiate a data science project , which analyses the current employee data and find the core underlying causes of this performance issues. Mr. Brain, being a data scientist himself, expects the findings of this project will help him to take right course of actions. He also expects a clear indicators of non performing employees, so that any penalization of non-performing employee, if required, may not significantly affect other employee morals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b7ae9",
   "metadata": {},
   "source": [
    "# Understanding the Problem Statement in this Business Case:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f9ef4",
   "metadata": {},
   "source": [
    "- The Company motive is to analyse and to find out the peformance of the employee, in order to get a clear indicator about which employees are performing well and which employees are not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef52de2",
   "metadata": {},
   "source": [
    "## Clients expectations from this project:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2dfd14",
   "metadata": {},
   "source": [
    "(1). **Department wise performances**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50376f",
   "metadata": {},
   "source": [
    "- After in-depth analysis, reports shows that **Sales, Human Resource, Development,  Research and Development and Finance departments have a performance rating of '3' which according to business standards is Satisfactory.**\n",
    "- **Data Science has employee ratings of '3' and '4', but it has some employees having a rating of '2', which according to business standard is unsatisfactory.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ffbb7",
   "metadata": {},
   "source": [
    "(2). **Top 3 Important Factors effecting employee performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0d0bc",
   "metadata": {},
   "source": [
    "- Emp Environment Satisfaction\n",
    "- Years Since Last Promotion\n",
    "- Emp Department."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde6e728",
   "metadata": {},
   "source": [
    "(3). **A trained model which can predict the employee performance based on factors as inputs. This will be used to hire employees**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99968625",
   "metadata": {},
   "source": [
    "Best performing models to predict the performance of the employees are with accuracy scores are:\n",
    "\n",
    "- **Random Forest(tuned)** - 97%\n",
    "- **Gradient Boosting** - 96%\n",
    "- **K- Nearest Neighbour** - 91.33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea6f20",
   "metadata": {},
   "source": [
    "(4). **Recommendations to improve the employee performance based on insights from analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057acc39",
   "metadata": {},
   "source": [
    "- Promote Employees more often in order to make them feel more job oriented.\n",
    "- Environment in which the employees work plays a significant role as it affects mental health which can result in performance drop, so improve environment in which the employee works by giving Flexible working hours, Constructive feedback, Positive Company Culture, Refreshment area and many more fun activities.\n",
    "- Employee may be want to switch department in order to grow but aren't able to do so, also results in declining performance.\n",
    "- Company should focus on these things in order to boost up performance of employees, as such employees will give excellent performance, more in numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933554f",
   "metadata": {},
   "source": [
    "# Requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c93cd",
   "metadata": {},
   "source": [
    "- This data is a dummy data given shared by IABAC for project analysis, where the data source is IABAC™.\n",
    "- The data is based on INX Future Inc. It is one of the leading data analytics and automation solutions provider with over 15 years of global business presence. \n",
    "- INX is consistently rated as top 20 best employers past 5 years. \n",
    "- This project was done in multiple platforms which includes Jupiter notebook and VSCode with python platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8860896",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75e723",
   "metadata": {},
   "source": [
    "- Complete Domain analysis was done on each and every feature to squeeze out maximum information that would help in analyzing.\n",
    "- Feature was divided into categorical and Numerical in order to perform analysis.\n",
    "- The features tell the relation between the dependent and independent variables.\n",
    "- Feature importance was used to bring out the most important feature which affects in the companies growth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801416b",
   "metadata": {},
   "source": [
    "# Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a7d91",
   "metadata": {},
   "source": [
    "- Age\n",
    "- DistanceFromHome\n",
    "- EmpHourlyRate\n",
    "- NumCompaniesWorked\n",
    "- EmpLastSalaryHikePercent\n",
    "- TotalWorkExperienceInYears\n",
    "- TrainingTimesLastYear\n",
    "- ExperienceYearsAtThisCompany\n",
    "- ExperienceYearsInCurrentRole\n",
    "- YearsSinceLastPromotion\n",
    "- YearsWithCurrManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068db8f2",
   "metadata": {},
   "source": [
    "# Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3408ad4",
   "metadata": {},
   "source": [
    "- EmpNumber\n",
    "- Gender\n",
    "- EducationBackground\n",
    "- MaritalStatus\n",
    "- EmpDepartment\n",
    "- EmpJobRole\n",
    "- BusinessTravelFrequency\n",
    "- OverTime\n",
    "- Attrition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c7eab",
   "metadata": {},
   "source": [
    "# Ordinal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d1487",
   "metadata": {},
   "source": [
    "- EmpEducationLevel\n",
    "- EmpEnvironmentSatisfaction\n",
    "- EmpJobInvolvement\n",
    "- EmpJobLevel\n",
    "- EmpJobSatisfaction\n",
    "- EmpRelationshipSatisfaction\n",
    "- EmpWorkLifeBalance\n",
    "- PerformanceRating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9afa9f",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f01983",
   "metadata": {},
   "source": [
    "### Data Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dee0c7",
   "metadata": {},
   "source": [
    "**External**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f7c81",
   "metadata": {},
   "source": [
    "- The data was extracted from the link provided by IABAC.\n",
    "- This data is from INX future Inc, where they wanted to explore Machine learning in order to benifit their organization.\n",
    "- The provider had demanded certain reports that need to be speecified and executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a77e0",
   "metadata": {},
   "source": [
    "**Processed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d28262",
   "metadata": {},
   "source": [
    "- This dataset went under many analysis process in order to extract insights that would be helpful for the organization.\n",
    "- Various Visualization Techniques as well as Pre-processing techniques were used to transform the raw dataset into a proper model building dataset.\n",
    "- Many trial and error have been performed in order to achieve the maximum results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b18de1",
   "metadata": {},
   "source": [
    "**Raw**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1a250",
   "metadata": {},
   "source": [
    "- This dataset was in raw excel form.\n",
    "- This data set had a collection of Employee details such as (Age,Gender,job role, etc)\n",
    "- This Raw data set has 1200 rows and 28 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ef20d",
   "metadata": {},
   "source": [
    "# Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654838c",
   "metadata": {},
   "source": [
    "- **Pandas** - Pandas is a popular Python library for data analysis. It is not directly related to Machine Learning. As we know that the dataset must be prepared before training. In this case, Pandas comes handy as it was developed specifically for data extraction and preparation. It provides high-level data structures and wide variety tools for data analysis. It provides many inbuilt methods for grouping, combining and filtering data.\n",
    "- **Numpy** - NumPy is a very popular python library for large multi-dimensional array and matrix processing, with the help of a large collection of high-level mathematical functions. It is very useful for fundamental scientific computations in Machine Learning. It is particularly useful for linear algebra, Fourier transform, and random number capabilities.\n",
    "- **Seaborn** - Seaborn is another open-source Python library, one that is based on Matplotlib (which focuses on plotting and data visualization) but features Pandas’ data structures. Seaborn is often used in ML projects because it can generate plots of learning data. Of all the Python libraries, it produces the most aesthetically pleasing graphs and plots, making it an effective choice if you’ll also use it for marketing and data analysis.\n",
    "- **Scipy** - SciPy is a very popular library among Machine Learning enthusiasts as it contains different modules for optimization, linear algebra, integration and statistics. There is a difference between the SciPy library and the SciPy stack. The SciPy is one of the core packages that make up the SciPy stack. SciPy is also very useful for image manipulation.  \n",
    "- **Scikit-learn** - Scikit-learn is one of the most popular ML libraries for classical ML algorithms. It is built on top of two basic Python libraries, viz., NumPy and SciPy. Scikit-learn supports most of the supervised and unsupervised learning algorithms. Scikit-learn can also be used for data-mining and data-analysis, which makes it a great tool who is starting out with ML\n",
    "- **Matplotlib** - Matplotlib is a very popular Python library for data visualization. Like Pandas, it is not directly related to Machine Learning. It particularly comes in handy when a programmer wants to visualize the patterns in the data. It is a 2D plotting library used for creating 2D graphs and plots.  It provides various kinds of graphs and plots for data visualization, viz., histogram, error charts, bar chats, etc, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab49a7",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6988d3",
   "metadata": {},
   "source": [
    "- **Univariate -** Univariate analysis is the simplest kind of data analysis in the field of statistics. This could be either descriptive or inferential in nature as is the case in any data analysis in statistics. The key thing about the univariate analysis to remember is that there is only one data involved here. While the univariate analysis may be easy to analyze and also is not complex, at times it may end up giving some misleading information especially if there are more variables involved. In this case, you need to move to the bivariate and the multivariate analysis that will be capable of analyzing the data better.\n",
    "- **Bivariate Analysis -** It is a methodical statistical technique applied to a pair of variables (features/ attributes) of data to determine the empirical relationship between them. In order words, it is meant to determine any concurrent relationship between different variables.\n",
    "- **Multivariate Analysis -** Multiple regression is the most commonly utilized multivariate technique. It examines the relationship between a single metric dependent variable and two or more metric independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4cef7",
   "metadata": {},
   "source": [
    "- Explaratory Data Analysis was done to investigate the data and summarize the key insights that will give the basic understanding of the data, it's distribution, null values and much more. \n",
    "- Data Exploration was done through using Graphs, Plots, charts etc.\n",
    "- Many Insights were derived through analyzing each features plotting it against each other, comparing and finding out the root of the features and what does these feature means to the company\n",
    "- In general, one of the first few steps in exploring the data would be to have a rough idea of how the features are distributed with one another. To do so, we shall invoke the familiar distplot function from the Seaborn plotting library. - The distribution has been done by both numerical features, it will show the overall idea about the density and majority of data present in a different level.\n",
    "- EDA was done on both Continous and Numerical features and insights were drawn out such as\n",
    "- In General, Most of Employees work up to 5 years in this company. Most of the employees get 11% to 15% of salary hike in this company.\n",
    "- Employees are worked in the multiple companies up to 8 companies where most of the employees worked up to 2 companies before getting to work here.\n",
    "- The age distribution is starting from 18 to 60 where the most of the employees are laying between 30 to 40 age count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d57c2",
   "metadata": {},
   "source": [
    "- **Library Used:** Matplotlib & Seaborn\n",
    "- **Plots Used:** Histplot, Lineplot, CountPlot, Barplot\n",
    "- **Tip:** All Observation or insights written below the plots\n",
    "\n",
    "**CONCLUSION**\n",
    "- There are some features are positively correlated with performance rating( Target variable) such as Emp Environment, Emp Satisfaction, Emp Last Salary Hike Percent, Emp Work Life Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73bf3a",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28fda7",
   "metadata": {},
   "source": [
    "# Basic Check, Duplicates and Statistical Measures.\n",
    "- All Basic checks have been successfully verified.\n",
    "- There is no duplicate values present in the data.\n",
    "- Their is no constant column is present in Numerical as well as categoriacl data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5e5ad",
   "metadata": {},
   "source": [
    "**INSIGHTS FROM CHECKING THE DISTRIBUTION OF CONTINUOUS FEATURES**\n",
    "- The feature Age can be considered as Normally distributed.\n",
    "- The features DistanceFromHome,EmpLastSalaryHikePercent,TotalWorkExperienceInYears, ExperienceYearsAtThisCompany,ExperienceYearsInCurrentRole, YearsSinceLastPromotion,YearsWithCurrManager are not Normally distributed and are skewed distribution mostly Right skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126e31f",
   "metadata": {},
   "source": [
    "**INSIGHTS FROM DEPARTMENT WISE PERFORMANCE RATING**\n",
    "- Sales: The performance rating 3 has the maximum counts, the performance rating 4 has the minimum counts.\n",
    "- Human Resources: The performance rating 3 has the maximum counts, the performance rating 4 has the minimum counts.\n",
    "- Development: The performance rating 3 has the maximum counts, the performance rating 2 has the minimum counts.\n",
    "- Data Science: The performance rating 3 has the maximum counts, the performance rating 2 and 4 has almost same minimum counts.\n",
    "- Research & Development: The performance rating 3 has the maximum counts, the performance rating 4 has the minimum count.\n",
    "- Finance: The performance rating 3 has the maximum counts, the performance rating 4 has the minimum counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05b225",
   "metadata": {},
   "source": [
    "**Kurtosis and Skeweness of Numerical Feature was also analyzed**\n",
    "- Checking weather the data is Normally distributed or Not with Skewness and Kurtosis,\n",
    "\n",
    "YearsSinceLastPromotion, This column is skewed:\n",
    "- skewness for YearsSinceLastPromotion: 1.9749315589155791\n",
    "- kurtosis for YearsSinceLastPromotion: 3.5390800793468817\n",
    "\n",
    "**Distribution of Mean**\n",
    "- Distribution of mean is close to guassian distribution with mean value around 9 to 9.5, we can say that around 80% feature mean lies between 8 to 12 and the range is 4 to 20.\n",
    "\n",
    "**Distribution of Median**\n",
    "- Distribution of median is normally distributed curve.\n",
    "- The range lies between 0 to 8.\n",
    "- Maximum of the data lies between 2 to 4 which is considered as the median or the middle value.\n",
    "\n",
    "**Distribution of Standard Deviation**\n",
    "- Distribution of standard deviation of data also look like guassian distribution around 30% of feature standard deviation around the range of 3 3 to 20 and remaining 70% feature standard deviation in between 0 to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1067ce8",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a562c",
   "metadata": {},
   "source": [
    "Data underwent through various preprocessing techniques such as\n",
    "- **Checking missing values** - No missing values was present in the data.\n",
    "- **outliers detection** - Boxplot was used to detect outliers\n",
    "- **Categorical Encoding** - Typically, any structured dataset includes multiple columns – a combination of numerical as well as categorical variables. A machine can only understand the numbers. It cannot understand the text. That’s primarily the reason we need to convert categorical columns to numerical columns so that a machine learning algorithm understands it. This process is called categorical encoding. Two techniques were used in encoding which are:-\n",
    "1. One hot encoding -  One hot encoding is a process of converting categorical data variables so they can be provided to machine learning algorithms to improve predictions.\n",
    "2. Categorical Encoding - Label Encoding is a popular encoding technique for handling categorical variables. In this technique, each label is assigned a unique integer based on alphabetical ordering.\n",
    "- **Feature Transformation** - In YearsSinceLastPromotion some skewed & kurtosis is present, so we are use Square Root Transformation techinque.\n",
    "- **Square root transformation:** Square root transformation is one of the many types of standard transformations.This transformation is used for count data (data that follow a Poisson distribution) or small whole numbers. Each data point is replaced by its square root. Negative data is converted to positive by adding a constant, and then transformed.\n",
    "- **Data Scaling** - Data has been scaled with the use of MinMax Scaler\n",
    "- **Feature Importance** - Feature importance has been done to find out the most important feature which affects the organization most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc28a2",
   "metadata": {},
   "source": [
    "# Future Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c03c7",
   "metadata": {},
   "source": [
    "- **Dropping unique and constant feature:** Dropping employee number because this is a constant column as well as Years Since Last Promotion.\n",
    "- **Checking Correlation:** Checking correlation with the help of heat map, and we viewed that there was high correlation between Year Since Lst Promotion and Year Since Last Promotion Square, so we dropped Years Since Last Promotion because we have created a new feaure using Square root transformation.\n",
    "- **Heatmap:** A heatmap is a graphical representation of data that uses a system of color-coding to represent different values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3fd8d3",
   "metadata": {},
   "source": [
    "# Model Creation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67118312",
   "metadata": {},
   "source": [
    "- Defining Dependant and Independant Features\n",
    "\n",
    "- Balancing the data: The data is imbalance, so we need to balance using SMOTE technique.\n",
    "**SMOTE:** SMOTE (synthetic minority oversampling technique) is one of the most commonly used oversampling methods to solve the imbalance problem. It aims to balance class distribution by randomly increasing minority class examples by replicating them. SMOTE synthesises new minority instances between existing minority instances.\n",
    "- Splitting Training And Testing Data: 75% data use for training & 25% data used for testing\n",
    "\n",
    "**Algorithm:** A machine learning algorithm is the method by which the AI system conducts its task, generally predicting output values from given input data. \n",
    "\n",
    "**AIM**: Create a sweet spot model (Low bias, Low variance)\n",
    "\n",
    "HERE WE WILL BE EXPERIMENTING WITH SIX MACHINE LEARNING ALGORITHM\n",
    "- Logistic Regression\n",
    "- Support Vector Machine (SVM)\n",
    "- K-nearest neighbour (Knn)\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "\n",
    "But the best performing model to predict the performance rating of the employees are **K- Nearest Neighbour, Random Forest(tuned) and Gradient Boosting**\n",
    "\n",
    "- **K-nearest neighbour** is a simple machine learning algorithm also known as KNN or k-NN, it is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point.The KNN algorithm has no explicit training step and all the work happens during prediction.Hence, it is also known as Lazy algorithm.\n",
    "- **Random forest** is a machine learning algorithm.It utilizes ensemble learning, which is a technique that combines many classifiers to provide solutions to complex problems.It consists of many decision trees. The ‘forest’ generated by the random forest algorithm is trained through bagging or bootstrap aggregating. Bagging is an ensemble meta-algorithm that improves the accuracy of machine learning algorithms.It’s more accurate than the decision tree algorithm.\n",
    "- **Gradient Boosting** is a powerful boosting algorithm that combines several weak learners into strong learners.The main idea behind this algorithm is to build models sequentially and these subsequent models try to reduce the errors of the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2925a44",
   "metadata": {},
   "source": [
    "# Challenges Faced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc2479",
   "metadata": {},
   "source": [
    "- The Target feature had multiple output which clearly indicates that this is a multi classification task.\n",
    "- Conversion of multi-class into binary class in order to perform algorithms.\n",
    "- Have used PCA earlier in the dataset but it resulted in overfitting of scores that's why we had to skip it in order to achive a good score.\n",
    "- Performed various Trial and Error such as handling of all outliers, handling partial outliers, using various transformation methods such as reciprocal transformation, boxcox transformatiion, log transformation, tuning in feature engineering part and applying different methods in order to get optimum scores.\n",
    "- Performing Exploratory Data Analysis.\n",
    "- Selecting the best model for the given business case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601cac8",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29fc24",
   "metadata": {},
   "source": [
    "A lot of refference was used in the completion of this project in order to get an overview about features for preprocessing, Industrial standards for better understanding of performance ratings, and Model creation techniques for maximizing the clients need.\n",
    "- **GeekforGeeks.com**\n",
    "- **performyard.com**\n",
    "- **AnalyticsVidya.com**\n",
    "- **Coursera.com**\n",
    "- **jstor.com**\n",
    "\n",
    "All these sites helped in the understanding of domain related things which played key role in building and completion of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd5209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
